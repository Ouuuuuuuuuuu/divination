import streamlit as st
from openai import OpenAI
import concurrent.futures
from typing import List, Dict, Any
import datetime
import random
import time
import math
import os
# éœ€è¦å…ˆå®‰è£… lunar_python: pip install lunar_python
try:
    from lunar_python import Lunar, Solar
except ImportError:
    st.error("è¯·å®‰è£…ä¾èµ–: pip install lunar_python")
    Solar = None
    Lunar = None

# --- Global Setup ---
st.set_page_config(page_title="AI ç»¼åˆæ™ºèƒ½å¹³å°", page_icon="ğŸ¤–", layout="wide")

# Custom CSS (Merged)
st.markdown("""
<style>
    .model-card {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 10px;
        background-color: #f9f9f9;
        height: 100%;
    }
    .stChatMessage {
        background-color: transparent;
    }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] {
        height: 50px; background-color: #fff; border-radius: 5px;
        border: 1px solid #ddd; padding: 0 20px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #E3F2FD !important; color: #1565C0 !important;
        border: 1px solid #1565C0 !important; font-weight: bold;
    }
    .hexagram-box {
        background: white; padding: 20px; border-radius: 8px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05); border: 1px solid #eee;
    }
    .info-card {
        background: #f8f9fa; border-left: 4px solid #1565C0;
        padding: 10px 15px; margin-bottom: 10px; border-radius: 4px; font-size: 0.9em;
    }
    .intro-text {
        background-color: #FFFFFF; padding: 20px; border-radius: 10px;
        border: 1px solid #E0E0E0; margin-bottom: 20px; color: #444;
    }
</style>
""", unsafe_allow_html=True)

# --- Shared Helpers ---

def get_api_key():
    """Unified API key retrieval."""
    # Try secrets first
    try:
        return st.secrets["api_keys"]["silicon_flow"]
    except (KeyError, FileNotFoundError):
        pass
    
    # Try explicit environment variable
    env_key = os.getenv("SILICONFLOW_API_KEY")
    if env_key:
        return env_key
        
    # Fallback to sidebar input
    return st.sidebar.text_input("SiliconFlow API Key", type="password", key="global_api_key_input")

def get_client(api_key):
    if not api_key:
        return None
    return OpenAI(
        api_key=api_key,
        base_url="https://api.siliconflow.cn/v1"
    )

# ==========================================
# APP 1: AI Roundtable (AI ä¼—è®®é™¢)
# ==========================================

def app_roundtable(api_key):
    PAGE_TITLE = "AI ä¼—è®®é™¢ (AI Roundtable)"
    
    # Updated Model List as requested
    PANEL_MODELS = [
        "deepseek-ai/DeepSeek-V3.2",
        "deepseek-ai/DeepSeek-R1",
        "moonshotai/Kimi-K2-Thinking",
        "zai-org/GLM-4.6", 
        "MiniMaxAI/MiniMax-M2"
    ]
    SECRETARY_MODEL = "deepseek-ai/DeepSeek-V3"

    # State Management for Roundtable
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "selected_models" not in st.session_state:
        st.session_state.selected_models = PANEL_MODELS

    st.title(f"ğŸ¤– {PAGE_TITLE}")
    st.markdown("è¿™é‡Œæ˜¯ **SiliconFlow** é©±åŠ¨çš„ AI åœ†æ¡Œä¼šè®®ã€‚æ‰€æœ‰æ¨¡å‹å°†åŒæ—¶å›ç­”æ‚¨çš„é—®é¢˜ï¼Œæˆ–è€…æ‚¨å¯ä»¥æŒ‡å®šæ¨¡å‹è¿›è¡Œè¾©è®ºã€‚")

    if not api_key:
        st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ API Key æˆ–åœ¨ `.streamlit/secrets.toml` ä¸­é…ç½®ã€‚")
        return

    client = get_client(api_key)

    # Roundtable specific sidebar controls
    with st.sidebar:
        st.divider()
        st.header("ğŸ® ä¼šè®®æ§åˆ¶")
        mode = st.radio("æ¨¡å¼", ["å…¨å‘˜å‘è¨€ (Broadcast)", "æŒ‡å®šè®¨è®º (Discussion)"])
        
        if mode == "æŒ‡å®šè®¨è®º (Discussion)":
            st.subheader("å”¤é†’æŒ‡å®šæ¨¡å‹")
            selected = st.multiselect(
                "é€‰æ‹©å‚ä¸ä¸‹ä¸€è½®å¯¹è¯çš„ AI:",
                PANEL_MODELS,
                default=PANEL_MODELS[:2]
            )
            st.session_state.selected_models = selected
        else:
            st.session_state.selected_models = PANEL_MODELS
        
        use_secretary = st.checkbox("å¯ç”¨ç§˜ä¹¦æ‘˜è¦ (Secretary)", value=False, help="å¯ç”¨åï¼ŒDeepSeek-V3 å°†åœ¨æ¯è½®å¯¹è¯å‰æ€»ç»“å†å²ã€‚")
        
        if st.button("æ¸…ç©ºå†å²"):
            st.session_state.messages = []
            st.rerun()

    # Chat Display
    chat_container = st.container()
    with chat_container:
        for msg in st.session_state.messages:
            role = msg["role"]
            name = msg.get("name", "")
            content = msg["content"]
            
            if role == "user":
                with st.chat_message("user"):
                    st.write(content)
            elif role == "assistant":
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(f"**{name}**")
                    st.markdown(content)
            elif role == "system":
                with st.expander(f"ğŸ“‹ ä¼šè®®çºªè¦ (ç”± {name} æä¾›)", expanded=False):
                    st.markdown(content)

    # Input & Logic
    user_input = st.chat_input("è¾“å…¥é—®é¢˜æˆ–æŒ‡ä»¤...")

    def generate_response_rt(client, model_name, history, system_prompt=None):
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        for msg in history:
            messages.append({"role": msg["role"], "content": msg["content"]})
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                stream=False,
                temperature=0.7,
            )
            return {"model": model_name, "content": response.choices[0].message.content, "error": None}
        except Exception as e:
            return {"model": model_name, "content": None, "error": str(e)}

    def summarize_context_rt(client, history):
        prompt = "è¯·ä½œä¸ºä¼šè®®ç§˜ä¹¦ï¼Œç®€è¦æ€»ç»“ä¸Šè¿°æ‰€æœ‰AIæ¨¡å‹çš„è®¨è®ºè¦ç‚¹å’Œç”¨æˆ·çš„æ ¸å¿ƒé—®é¢˜ã€‚ä¿ç•™å…³é”®åˆ†æ­§å’Œå…±è¯†ã€‚"
        temp_msgs = [{"role": m["role"], "content": f"[{m.get('name', 'User')}]: {m['content']}"} for m in history]
        temp_msgs.append({"role": "user", "content": prompt})
        try:
            response = client.chat.completions.create(model=SECRETARY_MODEL, messages=temp_msgs, temperature=0.5)
            return response.choices[0].message.content
        except Exception as e:
            return f"ç§˜ä¹¦æ¨¡å‹æ— æ³•æ€»ç»“: {e}"

    if user_input:
        st.session_state.messages.append({"role": "user", "name": "User", "content": user_input})
        st.rerun()

    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        active_models = st.session_state.selected_models
        if not active_models:
            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå›ç­”ï¼")
            st.stop()
            
        current_history = st.session_state.messages
        if use_secretary and len(current_history) > 5:
            with st.status("ğŸ‘©â€ğŸ’¼ ç§˜ä¹¦ (DeepSeek-V3) æ­£åœ¨æ•´ç†ä¼šè®®èƒŒæ™¯...", expanded=True) as status:
                summary = summarize_context_rt(client, current_history[:-1])
                st.session_state.messages.insert(-1, {"role": "system", "name": "Secretary", "content": f"**èƒŒæ™¯æ‘˜è¦**: {summary}"})
                status.update(label="èƒŒæ™¯æ•´ç†å®Œæ¯•", state="complete", expanded=False)
        
        st.markdown("### ğŸ™ï¸ AI æ­£åœ¨æ€è€ƒä¸­...")
        results = []
        cols = st.columns(len(active_models))
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(active_models)) as executor:
            future_to_model = {}
            for i, model in enumerate(active_models):
                with cols[i]:
                    st.markdown(f"**{model.split('/')[-1]}**")
                    spinner = st.spinner("æ€è€ƒä¸­...")
                clean_history = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages if m["role"] != "system"]
                future = executor.submit(generate_response_rt, client, model, clean_history)
                future_to_model[future] = model
                
            for future in concurrent.futures.as_completed(future_to_model):
                res = future.result()
                results.append(res)
        
        for res in results:
            if res["error"]:
                st.error(f"{res['model']} Error: {res['error']}")
            else:
                st.session_state.messages.append({
                    "role": "assistant",
                    "name": res["model"],
                    "content": res["content"]
                })
        st.rerun()


# ==========================================
# APP 2: AI Yi Jing (AI æ˜“å­¦å†³ç­–ç³»ç»Ÿ)
# ==========================================

def app_yijing(api_key):
    st.title("â˜¯ï¸ AI æ˜“å­¦å†³ç­–ç³»ç»Ÿ Pro")

    # é…ç½®ä¸å¸¸é‡
    MODELS = {
        "DeepSeek-R1 (æ¨ç†å¼º)": "deepseek-ai/DeepSeek-R1",
        "Kimi-K2-Thinking (ä¸­æ–‡ä¼˜)": "moonshotai/Kimi-K2-Thinking"
    }
    
    CITY_COORDINATES = {
        "åŒ—äº¬": 116.40, "ä¸Šæµ·": 121.47, "å¹¿å·": 113.26, "æ·±åœ³": 114.05,
        "æ­¦æ±‰": 114.30, "æˆéƒ½": 104.06, "è¥¿å®‰": 108.93, "æ²ˆé˜³": 123.43,
        "é‡åº†": 106.55, "å¤©æ´¥": 117.20, "æ­å·": 120.15, "å—äº¬": 118.79,
        "éƒ‘å·": 113.62, "é•¿æ²™": 112.93, "ç¦å·": 119.30, "æ˜†æ˜": 102.71,
        "è´µé˜³": 106.63, "å…°å·": 103.82, "å—å®": 108.32, "å“ˆå°”æ»¨": 126.63,
        "é•¿æ˜¥": 125.32, "çŸ³å®¶åº„": 114.48, "å¤ªåŸ": 112.53, "å‘¼å’Œæµ©ç‰¹": 111.65,
        "åˆè‚¥": 117.28, "å—æ˜Œ": 115.89, "æµå—": 117.00, "æµ·å£": 110.35,
        "æ‹‰è¨": 91.11, "è¥¿å®": 101.74, "é“¶å·": 106.27, "ä¹Œé²æœ¨é½": 87.62,
        "å°åŒ—": 121.50, "é¦™æ¸¯": 114.17, "æ¾³é—¨": 113.54,
        "è‡ªå®šä¹‰/æ‰‹åŠ¨è¾“å…¥": 0.0
    }
    TZ_CN = datetime.timezone(datetime.timedelta(hours=8))

    # --- æ˜“å­¦ Helpers ---
    def get_true_solar_time(dt, longitude):
        offset_minutes = (longitude - 120.0) * 4
        return dt + datetime.timedelta(minutes=offset_minutes)

    def get_ganzhi_info(dt_solar):
        if not Solar: return {}
        solar = Solar.fromYmdHms(dt_solar.year, dt_solar.month, dt_solar.day, dt_solar.hour, dt_solar.minute, dt_solar.second)
        lunar = solar.getLunar()
        ganzhi_year = lunar.getYearInGanZhi()
        ganzhi_month = lunar.getMonthInGanZhi()
        ganzhi_day = lunar.getDayInGanZhi()
        ganzhi_time = lunar.getTimeInGanZhi()
        info = {
            "str": f"{ganzhi_year}å¹´ {ganzhi_month}æœˆ {ganzhi_day}æ—¥ {ganzhi_time}æ—¶",
            "lunar_str": f"å†œå†{lunar.getMonthInChinese()}æœˆ{lunar.getDayInChinese()}",
            "month_num": lunar.getMonth(),
            "day_num": lunar.getDay(),
            "hour_zhi": ganzhi_time[1],
            "day_gan": ganzhi_day[0],
            "day_zhi": ganzhi_day[1],
            "solar_term": lunar.getPrevJieQi().getName() if lunar.getPrevJieQi() else "éèŠ‚æ°”æ—¥"
        }
        dizhi_list = list("å­ä¸‘å¯…å¯è¾°å·³åˆæœªç”³é…‰æˆŒäº¥")
        info['hour_idx'] = dizhi_list.index(info['hour_zhi'])
        return info

    class DivinationEngine:
        @staticmethod
        def get_seed():
            return int(time.time() * 1000000)

        @staticmethod
        def cast_liuyao_coin():
            random.seed(DivinationEngine.get_seed())
            results = []
            display_lines = []
            for _ in range(6):
                coins = [random.randint(0, 1) for _ in range(3)] 
                sum_val = sum(coins)
                if sum_val == 1:
                    val, name, symbol = 1, "å°‘é˜³", "â–…â–…â–…â–…â–…"
                elif sum_val == 2:
                    val, name, symbol = 0, "å°‘é˜´", "â–…â–…ã€€â–…â–…"
                elif sum_val == 3:
                    val, name, symbol = 3, "è€é˜³ O", "â–…â–…â–…â–…â–… O"
                else:
                    val, name, symbol = 2, "è€é˜´ X", "â–…â–…ã€€â–…â–… X"
                results.append(val)
                display_lines.append({"name": name, "symbol": symbol, "val": val})
            return results, display_lines

        @staticmethod
        def cast_meihua(n1, n2, time_num):
            upper = n1 % 8 or 8
            lower = n2 % 8 or 8
            moving = (n1 + n2 + time_num) % 6 or 6
            trigrams = {1:"ä¹¾", 2:"å…‘", 3:"ç¦»", 4:"éœ‡", 5:"å·½", 6:"å", 7:"è‰®", 8:"å¤"}
            nature = {1:"å¤©", 2:"æ³½", 3:"ç«", 4:"é›·", 5:"é£", 6:"æ°´", 7:"å±±", 8:"åœ°"}
            return {
                "upper": trigrams[upper], "upper_nature": nature[upper],
                "lower": trigrams[lower], "lower_nature": nature[lower],
                "moving": moving, "nums": (n1, n2)
            }

    def generate_system_prompt(method, user_profile, ganzhi_info):
        gender_str = user_profile['gender'] if user_profile['gender'] != "æœªæä¾›" else "æœªçŸ¥"
        bazi_desc = "æœªæä¾›"
        if user_profile['bazi_year'] or user_profile['bazi_day']:
            bazi_desc = f"å¹´æŸ±({user_profile['bazi_year']}) æœˆæŸ±({user_profile['bazi_month']}) æ—¥æŸ±({user_profile['bazi_day']}) æ—¶æŸ±({user_profile['bazi_hour']})"
        elif user_profile['birth_year']:
             bazi_desc = f"å‡ºç”Ÿå¹´ä»½: {user_profile['birth_year']}"

        base_prompt = f"""
        ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­å›½ä¼ ç»Ÿæœ¯æ•°çš„å¤§å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¸¥è°¨çš„æ—¶ç©ºä¸å‘½ä¸»ä¿¡æ¯è¿›è¡Œæ¨æ¼”ã€‚
        ã€æ—¶ç©ºèƒ½é‡ã€‘
        - çœŸå¤ªé˜³æ—¶å¹²æ”¯ï¼š{ganzhi_info.get('str', 'æœªçŸ¥')}
        - å†œå†ï¼š{ganzhi_info.get('lunar_str', 'æœªçŸ¥')}
        - èŠ‚æ°”ï¼š{ganzhi_info.get('solar_term', 'æœªçŸ¥')}
        ã€å‘½ä¸»ä¿¡æ¯ã€‘
        - æ€§åˆ«ï¼š{gender_str}
        - å‘½ç†å…«å­—/å¹´å‘½ï¼š{bazi_desc}
        - æ‰€åœ¨ç»åº¦ï¼š{user_profile['longitude']}
        ã€æ ¸å¿ƒåŸåˆ™ã€‘
        1. **æ‹’ç»æ¨¡æ£±ä¸¤å¯**ï¼šè¯·æ ¹æ®äº”è¡Œæ—ºè¡°ç»™å‡ºå€¾å‘æ€§åˆ¤æ–­ã€‚
        2. **ä¸“ä¸šæœ¯è¯­**ï¼šå¿…é¡»åˆ†ææœˆä»¤ï¼ˆæ—ºç›¸ä¼‘å›šæ­»ï¼‰ã€æ—¥è¾°ï¼ˆç”Ÿå…‹å†²åˆï¼‰ã€ç©ºäº¡ã€ç¥ç…ã€‚
        3. **ç»“åˆçœŸå¤ªé˜³æ—¶**ï¼šæ’ç›˜ä¾æ®çš„æ˜¯å½“åœ°çœŸå®çš„å¤ªé˜³ä½ç½®ï¼Œè€Œéæ ‡å‡†åŒ—äº¬æ—¶é—´ã€‚
        """
        if method == "å…­çˆ»":
            return base_prompt + "\nã€å…­çˆ»ç‰¹åŒ–æŒ‡ä»¤ã€‘1. è‡ªåŠ¨è£…å¦ï¼šç¡®å®šä¸–çˆ»ã€åº”çˆ»ã€å…­äº²ã€‚2. å–ç”¨ç¥ï¼šæ ¹æ®é—®é¢˜é€‰å–ç”¨ç¥ã€‚3. åˆ†æåŠ¨çˆ»ã€‚"
        elif method == "æ¢…èŠ±":
            return base_prompt + "\nã€æ¢…èŠ±æ˜“æ•°ç‰¹åŒ–æŒ‡ä»¤ã€‘1. åŒºåˆ†ä½“ç”¨ã€‚2. åˆ†æäº”è¡Œç”Ÿå…‹ã€‚3. ç»“åˆå½“ä¸‹æ—¶é—´ã€‚"
        elif method == "å¥‡é—¨":
            return base_prompt + "\nã€å¥‡é—¨éç”²ç‰¹åŒ–æŒ‡ä»¤ã€‘1. è„‘ä¸­æ’ç›˜ï¼ˆæ—¶å®¶å¥‡é—¨ï¼‰ã€‚2. æ‰¾ç”¨ç¥ã€‚3. åˆ†æå®«ä½ã€‚4. å†³ç­–å»ºè®®ã€‚"
        elif method == "å¤§å…­å£¬":
            return base_prompt + "\nã€å¤§å…­å£¬ç‰¹åŒ–æŒ‡ä»¤ã€‘1. ç¡®å®šæœˆå°†ã€‚2. æ’ç›˜ï¼ˆå¤©åœ°ç›˜ã€å››è¯¾ã€ä¸‰ä¼ ï¼‰ã€‚3. æ–­è¯¾ã€‚"
        elif method == "å¤ªä¹™":
            return base_prompt + "\nã€å¤ªä¹™ç¥æ•°ç‰¹åŒ–æŒ‡ä»¤ã€‘1. è®¡ç®—ç§¯å¹´ä¸å¤ªä¹™å±€ã€‚2. æ¨æ¼”ä¸»å®¢ã€‚3. å®šæ ¼å±€ã€‚4. æ–­å¤§åŠ¿ã€‚"
        elif method == "å°å…­å£¬":
            return base_prompt + "\nã€å°å…­å£¬ç‰¹åŒ–æŒ‡ä»¤ã€‘1. ç»“åˆå¹´æœˆæ—¥æ—¶æ¨å¯¼ä¸‰å®«ã€‚2. è§£é‡Šè½å®«æ·±æ„ã€‚"
        return base_prompt

    def stream_ai_analysis(prompt, system_prompt, model_key):
        if not api_key:
            st.error("âš ï¸ æœªæ£€æµ‹åˆ° API Keyã€‚")
            return
        
        client = get_client(api_key)
        
        st.markdown("---")
        st.markdown("#### ğŸ“œ å¤§å¸ˆæ‰¹æ–­")
        reasoning_expander = st.expander("ğŸ‘ï¸ å‡ç¥æ¨æ¼” (AI æ€è€ƒè¿‡ç¨‹)", expanded=True)
        reasoning_area = reasoning_expander.empty()
        content_area = st.empty()
        full_reasoning = ""
        full_content = ""
        
        try:
            response = client.chat.completions.create(
                model=model_key,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
                stream=True
            )
            for chunk in response:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                    full_reasoning += delta.reasoning_content
                    reasoning_area.markdown(f"*{full_reasoning}*")
                if hasattr(delta, 'content') and delta.content:
                    full_content += delta.content
                    content_area.markdown(full_content + "â–Œ")
            content_area.markdown(full_content)
        except Exception as e:
            st.error(f"è¿æ¥ä¸­æ–­: {str(e)}")

    # --- Sidebar: User Settings ---
    with st.sidebar:
        st.divider()
        st.header("ğŸ› ï¸ æ˜“å­¦å‚æ•°")
        with st.expander("ğŸ‘¤ å‘½ä¸»ä¿¡æ¯ (å¯é€‰)", expanded=False):
            gender = st.selectbox("æ€§åˆ«", ["æœªæä¾›", "ç”·", "å¥³"], index=0)
            input_method = st.radio("è¾“å…¥æ–¹å¼", ["ä»…å¹´ä»½", "è¯¦ç»†å››æŸ±(å…«å­—)"], index=0)
            birth_year = None
            bazi_year = bazi_month = bazi_day = bazi_hour = ""
            if input_method == "ä»…å¹´ä»½":
                if st.checkbox("è¾“å…¥å‡ºç”Ÿå¹´ä»½"):
                    birth_year = st.number_input("å‡ºç”Ÿå¹´ä»½", 1920, 2030, 1990)
            else:
                c1, c2 = st.columns(2)
                bazi_year = c1.text_input("å¹´æŸ±", placeholder="å¦‚: ç”²å­")
                bazi_month = c2.text_input("æœˆæŸ±", placeholder="å¦‚: ä¸™å¯…")
                bazi_day = c1.text_input("æ—¥æŸ±", placeholder="å¦‚: æˆŠåˆ")
                bazi_hour = c2.text_input("æ—¶æŸ±", placeholder="å¦‚: å£¬å­")

        with st.expander("ğŸŒ æ—¶ç©ºæ ¡å‡† (çœŸå¤ªé˜³æ—¶)", expanded=True):
            city_name = st.selectbox("é€‰æ‹©æ‰€åœ¨åœ°", list(CITY_COORDINATES.keys()), index=4) 
            if city_name == "è‡ªå®šä¹‰/æ‰‹åŠ¨è¾“å…¥":
                longitude = st.number_input("è¯·è¾“å…¥å½“åœ°ç»åº¦", value=116.40, format="%.2f")
            else:
                longitude = CITY_COORDINATES[city_name]
                st.caption(f"ğŸ“ {city_name} ç»åº¦: {longitude}Â°")
            
            now = datetime.datetime.now(TZ_CN)
            true_solar_time = get_true_solar_time(now.replace(tzinfo=None), longitude)
            st.caption(f"ğŸŒ çœŸå¤ªé˜³æ—¶: {true_solar_time.strftime('%H:%M:%S')}")

        ganzhi_info = get_ganzhi_info(true_solar_time) if Solar else {}
        if ganzhi_info:
            st.success(f"ğŸ“… {ganzhi_info['str']}\n\nğŸŒ™ {ganzhi_info['lunar_str']}")
        
        model_name = st.selectbox("é€‰æ‹©æ˜“å­¦ AI æ¨¡å‹", list(MODELS.keys()), index=0)
        selected_model = MODELS[model_name]

    # --- Main Yi Jing Content ---
    st.markdown("""
    <div class="intro-text">
    <h4>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ AI æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ</h4>
    <p>èåˆ<b>ä¼ ç»Ÿæœ¯æ•°</b>ä¸<b>æ·±åº¦æ¨ç† AI</b> (DeepSeek-R1/Kimi-K2)ã€‚é‡‡ç”¨çœŸå¤ªé˜³æ—¶ä¸ç»åº¦æ ¡å‡†ã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    if not Solar:
        st.error("âš ï¸ ç¼ºå°‘ `lunar_python` åº“ï¼Œæ— æ³•è¿›è¡Œæ’ç›˜è®¡ç®—ã€‚")
        return

    user_profile = {
        "gender": gender, "birth_year": birth_year,
        "bazi_year": bazi_year, "bazi_month": bazi_month, "bazi_day": bazi_day, "bazi_hour": bazi_hour,
        "longitude": longitude
    }

    tabs = st.tabs(["ğŸª™ å…­çˆ»çº³ç”²", "ğŸŒ¸ æ¢…èŠ±æ˜“æ•°", "ğŸ›¡ï¸ å¥‡é—¨éç”²", "ğŸŒŠ å¤§å…­å£¬", "ğŸŒŒ å¤ªä¹™ç¥æ•°", "ğŸ–ï¸ å°å…­å£¬"])

    # 1. å…­çˆ»
    with tabs[0]:
        st.subheader("å…­çˆ»çº³ç”²")
        col_q, col_btn = st.columns([3, 1])
        q_ly = col_q.text_input("è¯·è¾“å…¥é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šä¸‹ä¸ªæœˆè·³æ§½å»Aå…¬å¸å‰å‡¶å¦‚ä½•ï¼Ÿ", key="q_ly")
        if "ly_res" not in st.session_state: st.session_state.ly_res = None
        if col_btn.button("æ‘‡å¦èµ·ç›˜", use_container_width=True):
            if not q_ly: st.toast("âš ï¸ è¯·å…ˆè¾“å…¥é—®é¢˜")
            else:
                with st.spinner("å‡ç¥æ‘‡å¦ä¸­..."):
                    time.sleep(1)
                    raw, display = DivinationEngine.cast_liuyao_coin()
                    st.session_state.ly_res = {"raw": raw, "display": display, "q": q_ly}
        
        if st.session_state.ly_res:
            res = st.session_state.ly_res
            st.markdown("<div class='hexagram-box'>", unsafe_allow_html=True)
            for i in range(5, -1, -1):
                line = res['display'][i]
                color = "#D32F2F" if "é˜³" in line['name'] else "#1976D2"
                st.markdown(f"<div style='display:flex; justify-content:space-between; align-items:center; margin: 4px 0;'><span style='color:#999; font-size:12px; width:30px;'>å…­{i+1}</span><span style='color:{color}; font-weight:bold; font-size:18px; letter-spacing: 2px;'>{line['symbol']}</span><span style='color:#555; font-size:14px; width:80px; text-align:right;'>{line['name']}</span></div>", unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)
            if st.button("å¤§å¸ˆè§£å¦", key="btn_ly_ai"):
                sys_prompt = generate_system_prompt("å…­çˆ»", user_profile, ganzhi_info)
                user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{res['q']}\nå¦è±¡æ•°æ®ï¼š{[line['name'] for line in res['display']]}\nè¯·æ’ç›˜å¹¶æ–­å¦ã€‚"
                stream_ai_analysis(user_prompt, sys_prompt, selected_model)

    # 2. æ¢…èŠ±
    with tabs[1]:
        st.subheader("æ¢…èŠ±æ˜“æ•°")
        c1, c2 = st.columns(2)
        n1 = c1.number_input("ä¸Šå¦æ•°", 0, 999, 0)
        n2 = c2.number_input("ä¸‹å¦æ•°", 0, 999, 0)
        q_mh = st.text_input("æ‰€æµ‹ä¹‹äº‹", key="q_mh")
        if st.button("èµ·å¦", key="btn_mh"):
            if n1 == 0 or n2 == 0:
                n1, n2 = random.randint(1, 100), random.randint(1, 100)
                st.info(f"è‡ªåŠ¨æ„Ÿåº”æ•°å­—ï¼š{n1}, {n2}")
            res = DivinationEngine.cast_meihua(n1, n2, ganzhi_info['hour_idx'] + 1)
            c_a, c_b, c_c = st.columns(3)
            c_a.metric("æœ¬å¦", f"{res['upper']}{res['lower']}")
            c_b.metric("åŠ¨çˆ»", f"ç¬¬ {res['moving']} çˆ»")
            c_c.metric("äº”è¡Œ", f"ä¸Š{res['upper_nature']} ä¸‹{res['lower_nature']}")
            sys_prompt = generate_system_prompt("æ¢…èŠ±", user_profile, ganzhi_info)
            user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{q_mh}\nä¸Šå¦ï¼š{res['upper']}\nä¸‹å¦ï¼š{res['lower']}\nåŠ¨çˆ»ï¼š{res['moving']}\nè¯·æ–­å‰å‡¶ã€‚"
            stream_ai_analysis(user_prompt, sys_prompt, selected_model)

    # 3. å¥‡é—¨
    with tabs[2]:
        st.subheader("å¥‡é—¨éç”²")
        q_qm = st.text_input("å†³ç­–äº‹é¡¹", placeholder="ä¾‹å¦‚ï¼šæ˜å¤©å»è°ˆåˆ¤èƒ½å¦æˆåŠŸï¼Ÿæ–¹ä½åœ¨è¥¿åŒ—ã€‚", key="q_qm")
        if st.button("æ’ç›˜æ¼”å±€", key="btn_qm"):
            sys_prompt = generate_system_prompt("å¥‡é—¨", user_profile, ganzhi_info)
            user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{q_qm}\nå½“å‰çœŸå¤ªé˜³æ—¶å¹²æ”¯ï¼š{ganzhi_info['str']}\nè¯·ä»¥æ—¶å®¶å¥‡é—¨æ’ç›˜åˆ†æã€‚"
            stream_ai_analysis(user_prompt, sys_prompt, selected_model)

    # 4. å¤§å…­å£¬
    with tabs[3]:
        st.subheader("å¤§å…­å£¬")
        q_lr = st.text_input("å…­å£¬é—®äº‹", key="q_lr")
        if st.button("èµ·è¯¾åˆ†æ", key="btn_lr"):
            sys_prompt = generate_system_prompt("å¤§å…­å£¬", user_profile, ganzhi_info)
            user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{q_lr}\nå½“å‰çœŸå¤ªé˜³æ—¶å¹²æ”¯ï¼š{ganzhi_info['str']}\nå½“å‰èŠ‚æ°”ï¼š{ganzhi_info.get('solar_term','')}\nè¯·ç¡®å®šæœˆå°†ï¼Œæ¨å¯¼å¤©åœ°ç›˜ã€å››è¯¾ã€ä¸‰ä¼ ï¼Œæœ€åæ–­äº‹ã€‚"
            stream_ai_analysis(user_prompt, sys_prompt, selected_model)

    # 5. å¤ªä¹™
    with tabs[4]:
        st.subheader("å¤ªä¹™ç¥æ•°")
        q_ty = st.text_input("å¤ªä¹™é—®æµ‹", placeholder="ä¾‹å¦‚ï¼šæœªæ¥äº”å¹´è¡Œä¸šå‘å±•å¤§åŠ¿å¦‚ä½•ï¼Ÿ", key="q_ty")
        if st.button("å¤ªä¹™æ¼”å±€", key="btn_ty"):
            sys_prompt = generate_system_prompt("å¤ªä¹™", user_profile, ganzhi_info)
            user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{q_ty}\nå½“å‰çœŸå¤ªé˜³æ—¶å¹²æ”¯ï¼š{ganzhi_info['str']}\nè¯·è¿›è¡Œå¤ªä¹™ç§¯å¹´æ¨ç®—ï¼Œå®šå±€æ•°ï¼Œåˆ†ä¸»å®¢ï¼Œè®ºæ ¼å±€ã€‚"
            stream_ai_analysis(user_prompt, sys_prompt, selected_model)

    # 6. å°å…­å£¬
    with tabs[5]:
        st.subheader("å°å…­å£¬")
        q_xlr = st.text_input("é€Ÿé—®", key="q_xlr")
        if st.button("ææŒ‡ä¸€ç®—", key="btn_xlr"):
            m, d, h = ganzhi_info['month_num'], ganzhi_info['day_num'], ganzhi_info['hour_idx'] + 1
            states = ["å¤§å®‰", "ç•™è¿", "é€Ÿå–œ", "èµ¤å£", "å°å‰", "ç©ºäº¡"]
            idx_m = (m - 1) % 6
            idx_d = (idx_m + d - 1) % 6
            idx_h = (idx_d + h - 1) % 6
            result = states[idx_h]
            seq = f"{states[idx_m]} -> {states[idx_d]} -> {states[idx_h]}"
            st.success(f"ç»“æœï¼š{result}")
            st.caption(f"è·¯å¾„ï¼š{seq}")
            sys_prompt = generate_system_prompt("å°å…­å£¬", user_profile, ganzhi_info)
            user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{q_xlr}\næ¨æ¼”è·¯å¾„ï¼š{seq}\næœ€ç»ˆè½å®«ï¼š{result}\nè¯·è§£é‡Šå«ä¹‰ã€‚"
            stream_ai_analysis(user_prompt, sys_prompt, selected_model)

# ==========================================
# Main Navigation
# ==========================================

def main():
    st.sidebar.title("ğŸ”® åŠŸèƒ½å¯¼èˆª")
    app_mode = st.sidebar.radio("é€‰æ‹©åº”ç”¨", ["AI ä¼—è®®é™¢ (Roundtable)", "AI æ˜“å­¦å†³ç­– (Yi Jing)"])
    
    # Unified Key Retrieval
    api_key = get_api_key()

    if app_mode == "AI ä¼—è®®é™¢ (Roundtable)":
        app_roundtable(api_key)
    elif app_mode == "AI æ˜“å­¦å†³ç­– (Yi Jing)":
        app_yijing(api_key)

if __name__ == "__main__":
    main()
